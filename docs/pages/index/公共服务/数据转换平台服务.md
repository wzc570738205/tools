<!--
 * @Author: zhaoyawei
 * @Date: 2021-1-04 9:22:18
 * @LastEditors: zhaoyawei
 * @LastEditTime: 2020-12-04 15:10:38
-->
## 服务目的

该平台主要基于Alibaba开源项目dataX进行封装和二次开发，提供复杂网络环境下、丰富的异构数据源之间高速稳定的数据移动能力，以及繁杂业务背景下的数据同步解决方案。支持MySQL、Oracle、postgresql、sqlserver、hive、hbase、mongodb、clickhouse、kafka、restful等多种数据源之间的一键全增量同步解决方案。  
并且提供简单易用的操作界面datax-web服务，降低用户使用DataX的学习成本，缩短任务配置时间，避免配置过程中出错。用户可通过页面选择数据源即可创建数据同步任务，RDBMS数据源可批量创建数据同步任务，支持实时查看数据同步进度及日志并提供终止同步功能，集成并二次开发xxl-job可根据时间、自增主键增量同步数据。任务"执行器"支持集群部署，支持执行器多节点路由策略选择，支持超时控制、失败重试、失败告警、任务依赖，执行器CPU.内存.负载的监控等等。

## 快速使用
1、部署dataX：  
(1)、拉取代码：   
````
https://59.110.237.110/svn/项目/应用软件公共组件/数据调度/code/后端/DataX
````  
(2)、maven打包：  
````
mvn -U clean package assembly:assembly -Dmaven.test.skip=true
````  
(3)、将target/datax.tar.gz上传至规划的datax-web执行器所在服务器,并解压  
		注：服务器需要有jdk8以及python2运行环境  
(4)、自检脚本：  
````
python {YOUR_DATAX_HOME}/bin/datax.py {YOUR_DATAX_HOME}/job/job.json
````  
2、部署datax-web：   
(1)、拉取代码：  
````
https://59.110.237.110/svn/项目/应用软件公共组件/数据调度/code/后端/datax-web
````  
(2)、maven打包：  
````
mvn clean install 
````  
(3)、上传build/datax-web-{VERSION}.tar.gz至服务器，并解压  
````
tar -zxvf datax-web-{VERSION}.tar.gz
````  
(4)、进入解压后的目录，找到bin目录下面的install.sh文件，如果选择交互式的安装，则直接执行  
````
./bin/install.sh
````  
在交互模式下，对各个模块的package压缩包的解压以及configure配置脚本的调用，都会请求用户确认,可根据提示查看是否安装成功，如果没有安装成功，可以重复尝试；如果不想使用交互模式，跳过确认过程，则执行以下命令安装  
````
/bin/install.sh --force
````  
(5)、创建数据库，执行datax-web/bin/db/datax_web.sql  
(6)、修改datax-admin配置文件数据库配置: 
```
vi ./modules/datax-admin/conf/bootstrap.properties  
#Database  
#DB_HOST=  
#DB_PORT=  
#DB_USERNAME=  
#DB_PASSWORD=  
#DB_DATABASE=  
```
(7)、修改环境配置参数和邮件服务(可选)：  
````
vi ./modules/datax-admin/bin/env.properties 
````  
(8)、修改执行器datax-execute配置参数，指定PYTHON_PATH的路径，执行器支持分布式部署，调度中心datax-admin支持多种任务执行路由策略：  
```
vi /modules/datax-execute/bin/env.properties  
###执行datax的python脚本地址  
PYTHON_PATH=  
###保持和datax-admin服务的端口一致；默认是9527，如果没改datax-admin的端口，可以忽略,如果与datax-admin服务在同一台服务器，DATAX_ADMIN_HOST可以忽略  
DATAX_ADMIN_PORT=  
DATAX_ADMIN_HOST=  
```
(9)、启动服务：  
首先启动调度中心datax-admin：  
````
	./modules/datax-admin/bin/datax-admin.sh start
````  
然后分别启动各个执行器datax-execute：    
````
	./modules//datax-execute/bin/datax-executor.sh start
````  
4、部署datax-web-ui:  
(1)、拉取代码：  
````
https://59.110.237.110/svn/项目/应用软件公共组件/数据调度/code/前端/datax-web-ui  
````  
(2)、打包：  
````
npm run build:prod
````  
(3)、上传至服务器后，配置nginx代理
(4)、浏览器打开系统，使用默认密码登录  
```
userName：admin  
password：123456
```
## 使用流程介绍
1、创建数据源  
![](https://datax-web.oss-cn-hangzhou.aliyuncs.com/doc/add_datasource.png)
2、创建任务模版  
![](https://datax-web.oss-cn-hangzhou.aliyuncs.com/doc/template_list.png)
3、构建JSON脚本
(1)、步骤一，步骤二，选择第二步中创建的数据源，JSON构建目前支持的数据源有hive,mysql,oracle,postgresql,sqlserver,hbase,mongodb,clickhouse,kafka,restful，其它数据源的JSON构建正在开发中,暂时需要手动编写
![](https://datax-web.oss-cn-hangzhou.aliyuncs.com/doc/build.png)
(2)、字段映射
![](https://datax-web.oss-cn-hangzhou.aliyuncs.com/doc/mapping.png)
(3)、点击构建，生成json,此时可以选择复制json然后创建任务，选择datax任务，将json粘贴到文本框。也可以点击选择模版，直接生成任务。
![](https://datax-web.oss-cn-hangzhou.aliyuncs.com/doc/select_template.png)
4、批量创建任务
![](https://datax-web.oss-cn-hangzhou.aliyuncs.com/doc/batch_build_r.png)
![](https://datax-web.oss-cn-hangzhou.aliyuncs.com/doc/batch_build_w.png)
5、任务创建介绍（关联模版创建任务不再介绍，具体参考3. 构建JSON脚本）
#### 支持DataX任务,Shell任务，Python任务，PowerShell任务
![](https://datax-web.oss-cn-hangzhou.aliyuncs.com/doc/datax.png)

![](https://datax-web.oss-cn-hangzhou.aliyuncs.com/doc/shell.png)
- 阻塞处理策略：调度过于密集执行器来不及处理时的处理策略；
    - 单机串行：调度请求进入单机执行器后，调度请求进入FIFO队列并以串行方式运行；
    - 丢弃后续调度：调度请求进入单机执行器后，发现执行器存在运行的调度任务，本次请求将会被丢弃并标记为失败；
    - 覆盖之前调度：调度请求进入单机执行器后，发现执行器存在运行的调度任务，将会终止运行中的调度任务并清空队列，然后运行本地调度任务；
- 增量增新建议将阻塞策略设置为丢弃后续调度或者单机串行
    - 设置单机串行时应该注意合理设置重试次数(失败重试的次数*每次执行时间<任务的调度周期)，重试的次数如果设置的过多会导致数据重复，例如任务30秒执行一次，每次执行时间需要20秒，设置重试三次，如果任务失败了，第一个重试的时间段为1577755680-1577756680，重试任务没结束，新任务又开启，那新任务的时间段会是1577755680-1577758680

- 增量参数设置
	### 一、根据日期进行增量数据抽取：  
	#### 1、页面任务配置
	- 1、任务类型选DataX任务
	- 2、辅助参数选择时间自增
	- 3、增量开始时间选择，即sql中查询时间的开始时间，用户使用此选项方便第一次的全量同步。第一次同步完成后，该时间被更新为上一次的任务触发时间，任务失败不更新。
	- 4、增量时间字段,-DlastTime='%s' -DcurrentTime='%s' 先来解析下这段字符串
	````
		1.-D是DataX参数的标识符，必配
		2.-D后面的lastTime和currentTime是DataX json中where条件的时间字段标识符，必须和json中的变量名称保持一致
		3.='%s'是项目用来去替换时间的占位符，比配并且格式要完全一致
		4.注意-DlastTime='%s'和-DcurrentTime='%s'中间有一个空格，空格必须保留并且是一个空格
	````
	- 5、时间格式，可以选择自己数据库中时间的格式，也可以通过json中配置sql时间转换函数来处理
	#### 2、JSON配置
	datax.json  
	````
		{
		"job": {
			"setting": {
			"speed": {
				"channel": 16
			}
			},
			"content": [
			{
				"reader": {
				"name": "mysqlreader",
				"parameter": {
					"splitPk": "id",
					"username": "root",
					"password": "root",
					"column": [
					"*"

					],
					"connection": [
					{
						
						"jdbcUrl": [
						"jdbc:mysql://localhost:3306/test?characterEncoding=utf8"
						],
						"querySql": [
				"select * from test_list where operationDate >= FROM_UNIXTIME(${lastTime}) and operationDate < FROM_UNIXTIME(${currentTime})"
										]
					}
					]
				}
				},
				"writer": {
				"name": "mysqlwriter",
				"parameter": {
				
					"username": "root",
					"password": "123456",
					"column": [
					"*"
					],
					"batchSize": "4096",
					"connection": [
					{
						"jdbcUrl": "jdbc:mysql://localhost:3307/test?characterEncoding=utf8",
						"table": [
						"test_list"
						]
					}
					]
				}
				}
			}
			]
		}
		}
	````
	querySql解析
	````
	select * from test_list where operationDate >= ${lastTime} and operationDate < ${currentTime}
	````
	- 1.此处的关键点在${lastTime}，${currentTime}，${}是DataX动态参数的固定格式，lastTime，currentTime就是我们页面配置中 -DlastTime='%s' -DcurrentTime='%s'中的lastTime，currentTime，注意字段一定要一致。
	- 2.如果任务配置页面，时间类型选择为时间戳但是数据库时间格式不是时间戳，例如是：2019-11-26 11:40:57 此时可以用FROM_UNIXTIME(${lastTime})进行转换。
	```
	select * from test_list where operationDate >= FROM_UNIXTIME(${lastTime}) and operationDate < FROM_UNIXTIME(${currentTime})
	```
	### 二、根据自增Id进行增量数据抽取
	#### 1.页面任务配置
	- 1.任务类型选DataX任务
	- 2.辅助参数选择主键自增
	- 3.增量主键开始ID选择，即sql中查询ID的开始ID，用户使用此选项方便第一次的全量同步。第一次同步完成后，该ID被更新为上一次的任务触发时最大的ID，任务失败不更新。
	- 4.增量时间字段,-DstartId='%s' -DendId='%s' 先来解析下这段字符串
	```
	1.-D是DataX参数的标识符，必配
	2.-D后面的startId和endId是DataX json中where条件的id字段标识符，必须和json中的变量名称保持一致，endId是任务在每次执行时获取当前表maxId，也是下一次任务的startId
	3.='%s'是项目用来去替换时间的占位符，比配并且格式要完全一致
	4.注意-DstartId='%s'和-DendId='%s' 中间有一个空格，空格必须保留并且是一个空格
	5.reader数据源，选择任务同步的读数据源
	6.配置reader数据源中需要同步数据的表名及该表的主键
	```
	#### 2.JSON配置
	datax.json
	```
		{
	"job": {
		"setting": {
		"speed": {
			"channel": 3,
			"byte": 1048576
		},
		"errorLimit": {
			"record": 0,
			"percentage": 0.02
		}
		},
		"content": [
		{
			"reader": {
			"name": "mysqlreader",
			"parameter": {
				"username": "yRjwDFuoPKlqya9h9H2Amg==",
				"password": "yRjwDFuoPKlqya9h9H2Amg==",
				"splitPk": "",
				"connection": [
				{
					"querySql": [
					"select * from job_log where id>= ${startId} and id< ${endId}"
					],
					"jdbcUrl": [
					"jdbc:mysql://localhost:3306/datax_web"
					]
				}
				]
			}
			},
			"writer": {
			"name": "mysqlwriter",
			"parameter": {
				"username": "mCFD+p1IMsa0rHicbQohcA==",
				"password": "PhYxJmA/nuBJD1OxKTRzZH8sxuRddOv83hdqDOVR+i0=",
				"column": [
				"`id`",
				"`job_group`",
				"`job_id`",
				"`job_desc`",
				"`executor_address`",
				"`executor_handler`",
				"`executor_param`",
				"`executor_sharding_param`",
				"`executor_fail_retry_count`",
				"`trigger_time`",
				"`trigger_code`",
				"`trigger_msg`",
				"`handle_time`",
				"`handle_code`",
				"`handle_msg`",
				"`alarm_status`",
				"`process_id`",
				"`max_id`"
				],
				"connection": [
				{
					"table": [
					"job_log"
					],
					"jdbcUrl": "jdbc:mysql://47.98.125.243:3306/datax_web"
				}
				]
			}
			}
		}
		]
	}
	}
	```
	querySql解析
	```
	select * from job_log where id>= ${startId} and id< ${endId}
	```
	- 1.此处的关键点在${startId}，${endId}，${}是DataX动态参数的固定格式，startId，endId就是我们页面配置中 -DstartId='%s' -DendId='%s'中的startId，endId，注意字段一定要一致。
